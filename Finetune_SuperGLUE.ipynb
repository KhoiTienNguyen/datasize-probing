{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT4_NpW-TotE"
      },
      "source": [
        "# Welcome to `jiant`\n",
        "This notebook contains an example of fine-tuning a `bert-base-uncased` model on the MultiRC task using the simple `jiant` API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlM8H-WCoh9k"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rY-7weGtIEUX",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/nyu-mll/jiant.git\n",
        "# This Colab notebook already has its CUDA-runtime compatible versions of torch and torchvision installed\n",
        "!pip install -r jiant/requirements-no-torch.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJvvCXGoki7q",
        "outputId": "db1bdddf-5557-4415-a779-a42a4dbfd0e9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j78UDhA7UMzi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5hsmmr9eIJJt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/jiant\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UXYZHyyNGayI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import jiant.utils.python.io as py_io\n",
        "import jiant.proj.simple.runscript as simple_run\n",
        "import jiant.scripts.download_data.runscript as downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aow1wIIDUS4h"
      },
      "source": [
        "# Define task and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AEtgbtkRHDJE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# See https://github.com/nyu-mll/jiant/blob/master/guides/tasks/supported_tasks.md for supported tasks\n",
        "TASK_NAME = \"multirc\"\n",
        "\n",
        "# See https://huggingface.co/models for supported models\n",
        "HF_PRETRAINED_MODEL_NAME = \"bert-base-uncased\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDjg1tRNUk9r"
      },
      "source": [
        "# Create directories for task data and experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gxy_csM9UhhA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Remove forward slashes so RUN_NAME can be used as path\n",
        "MODEL_NAME = HF_PRETRAINED_MODEL_NAME.split(\"/\")[-1]\n",
        "RUN_NAME = f\"simple_{TASK_NAME}_{MODEL_NAME}\"\n",
        "EXP_DIR = \"/content/exp\"\n",
        "DATA_DIR = \"/content/exp/tasks\"\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(EXP_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tXDQ1P2Unfa"
      },
      "source": [
        "#Download data (uses `nlp` or direct download depending on task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HCQG8fEU4CU",
        "outputId": "17ea57cd-72e3-42ff-d6d8-3c1a4565b890",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded and generated configs for 'multirc' (1/1)\n"
          ]
        }
      ],
      "source": [
        "downloader.download_data([TASK_NAME], DATA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsInlNWLU5ZU"
      },
      "source": [
        "#Run simple `jiant` pipeline (train and evaluate on MultiRC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po0N521IHAjj",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "args = simple_run.RunConfiguration(\n",
        "    run_name=RUN_NAME,\n",
        "    exp_dir=EXP_DIR,\n",
        "    data_dir=DATA_DIR,\n",
        "    hf_pretrained_model_name_or_path=HF_PRETRAINED_MODEL_NAME,\n",
        "    tasks=TASK_NAME,\n",
        "    train_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    seed=42,\n",
        "    do_save=True\n",
        ")\n",
        "simple_run.run_simple(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEJ4OxuHcNaA"
      },
      "source": [
        "# Convert to PyTorch format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IeGtTdC6cT7U",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def remove_prefix(s, prefix):\n",
        "    assert s.startswith(prefix)\n",
        "    return s[len(prefix) :]\n",
        "\n",
        "def load_encoder_from_transformers_weights(\n",
        "    encoder, weights_dict\n",
        "):\n",
        "    \"\"\"Find encoder weights in weights dict, load them into encoder, return any remaining weights.\n",
        "    TODO: clarify how we know the encoder weights will be prefixed by transformer name.\n",
        "    Args:\n",
        "        encoder (PreTrainedModel): Transformer w/o heads (embedding layer + self-attention layer).\n",
        "        weights_dict (Dict): model weights.\n",
        "        return_remainder (bool): If True, return any leftover weights.\n",
        "    Returns:\n",
        "        Dict containing any leftover weights.\n",
        "    \"\"\"\n",
        "    remainder_weights_dict = {}\n",
        "    load_weights_dict = {}\n",
        "    encoder_prefix = 'bert.'\n",
        "    # Encoder\n",
        "    for k, v in weights_dict.items():\n",
        "        if k.startswith(encoder_prefix):\n",
        "            load_weights_dict[remove_prefix(k, encoder_prefix)] = v\n",
        "        elif k.startswith(encoder_prefix.split(\"-\")[0]):\n",
        "            # workaround for deberta-v2\n",
        "            # remove \"-v2\" suffix. weight names are prefixed with \"deberta\" and not \"deberta-v2\"\n",
        "            load_weights_dict[remove_prefix(k, encoder_prefix.split(\"-\")[0] + \".\")] = v\n",
        "        else:\n",
        "            remainder_weights_dict[k] = v\n",
        "    encoder.load_state_dict(load_weights_dict, strict=False)\n",
        "    # return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_3namKFcm5_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Change path to last model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28WPNFK-cQb5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "og_format = torch.load('last_model.p')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAo0mXwec15w",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "load_encoder_from_transformers_weights(model, og_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLkydPPlc4sh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/models/multirc/')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
